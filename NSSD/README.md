This portion of our summer project focuses on NSSD (Non-Speech Sound Detection) 
and integrating them with orthographic, verbatim transcriptions. 


Using CMU's PocketSphinx API, we are able to take in audio files and dissect them, 
isolating sounds which form the bases of NSS, such as 'uh', 'um', etc.


Then, taking in an orthographic transcription of the audio file we used initially, we can utilize the 
timestamps of these two sources in order to compile a hyper-linked transcription that includes both
NSS and the original transcription, in order. 


This project is still under construction and will not be fully functional until August 2023.


Authors:

Kevin Zhao       (github: kevinzhao79)
Dasang Dolma     (github: Dasangdolma)